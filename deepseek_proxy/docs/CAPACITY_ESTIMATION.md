# 智能菜谱应用容量与并发估算说明

> 目标：为本 DeepSeek 代理 + RAG（菜谱搜索/重排序）应用在 1 核 1GB 低配服务器上的并发、限流、Token TTL、连接池等参数提供科学、可审阅的估算依据，支撑后续配置与扩容策略。

---
## 1. 业务特征与使用行为假设

| 维度 | 假设值 | 说明 |
|------|--------|------|
| 累计注册用户 | ~10,000 | 最高上万级，存在高流失率 |
| DAU（日活） | 5%–20% 注册用户 | 早期可能仅 5%（≈500），成熟 10%–20%（≈1,000–2,000） |
| 峰值同时在线率（5分钟窗口） | 3%–8% DAU | 内容/工具类中值取 5% |
| 用户同时在线 (CCU) | 25 / 50 / 100 | 对应 DAU=500/1,000/2,000 三个场景 |
| 用户思考/阅读间隔 (Think Time) | 20–40 秒 | 用户查看答案或菜谱后再提问 |
| LLM 响应时长 (生成) | 25–40 秒 | 代理测试中观察的典型延迟 |
| 请求类型比例 | Chat 70% / 检索 20% / 其他 10% | Chat 最重，决定整体容量 |

> 注：这是一组“审阅用”参数。后续埋点可替换成真实统计再回算。

---
## 2. 基础公式：Little's Law

Little 定律：`L = λ * W`
- `L`: 系统中同时正在处理的请求数量（并发活跃请求）
- `λ`: 吞吐率（RPS: Requests Per Second）
- `W`: 平均单请求处理时长（秒）

对 Chat（最长、最重）：
- 平均处理时长 `W_chat ≈ 30s`
- 用户行为循环：一次请求 + 阅读/思考 → `W_chat + ThinkTime ≈ 30 + 30 = 60s`
- 单用户平均发起速率 `λ_user ≈ 1/60 ≈ 0.0167 req/s`

场景估算：
| 场景 | CCU (活跃用户) | 理论 Chat RPS = CCU * 0.0167 | 加上其他类型请求 (~+30%) | 总 RPS_peak |
|------|----------------|-------------------------------|--------------------------|-------------|
| 初期低活跃 | 25 | 0.42 | ≈0.55 | ~0.6 |
| 中等 | 50 | 0.83 | ≈1.08 | ~1.1 |
| 乐观增长 | 100 | 1.67 | ≈2.17 | ~2.2 |

=> 结论：**即便 CCU=100，总 RPS 峰值也可能低于 2.5 req/s。** 这是一个“重请求 + 长思考”的慢速交互系统，真正需要的稳定吞吐远低于典型 Web API。

---
## 3. 与当前配置的对比（现有 `config.toml`）

当前关键参数：
```
[auth]
token_ttl_seconds = 60

[deepseek]
timeout_seconds = 60

[deepseek.http_client]
pool_max_idle_per_host = 40

[quota]
save_interval = 25

[rate_limit]
requests_per_second = 20   # burst = 40
```

差异分析：
- 当前 `requests_per_second = 20` 明显高于估算的实际峰值需求（2.2 左右），属于**资源过度预留**。
- 突发桶 40 → 一次可放入 40 个长时间生成请求，对单核会造成队列尾部膨胀的风险（长尾）。
- TTL=60s 在典型 round >40s + 用户再思考情况下，第二轮很容易全部过期，导致额外登录开销与潜在 401。

---
## 4. 推荐分档配置

| 阶段 | 规模（DAU） | RPS | Burst | Token TTL | 每 Token 并发 | 说明 |
|------|-------------|-----|-------|-----------|---------------|------|
| 初期验证 | 100–200 | 6 | 12 | 120 | 1 | 少量请求，降低登录频率 |
| 早期增长 | 500–800 | 8 | 16 | 120–180 | 1 | 观测 p95，保持稳定 |
| 成熟小众 | 1,000–2,000 | 12 | 24 | 180 | 1–2 | 仅在延迟稳定时提高并发 |
| 扩容准备 | >2,000 | 水平扩容 | 按节点 | 180–300 | 1–2 | 不再提高单节点 RPS，改多实例 |

> 原则：**不盲目提升单机 RPS，用多实例水平扩展而不是让单核承担更多长时任务。**

---
## 5. 建议的参数调整（立即可行动）

最小修改（适合当前单核）：
```
[rate_limit]
requests_per_second = 12  # 代替 20

[auth]
token_ttl_seconds = 120   # 降低二轮 401

[deepseek]
timeout_seconds = 90      # 避免接近完成时被硬超时

[deepseek.http_client]
pool_max_idle_per_host = 30  # 与突发接近即可
```

可选预埋：
```
[auth]
per_token_concurrency = 1  # 未来若开启多并发可调到 2
```

---
## 6. 监控与触发条件（SLO/SLA 草案）

| 指标 | 触发告警条件 | 调整动作 |
|------|--------------|----------|
| p95 Chat 延迟 | > 60s 持续 10 分钟 | 下调 RPS 或检查上游拥塞 |
| 429 比例 | > 3% | RPS 略降或突发增至 2.5x（仅短期） |
| 401 比例 | > 2% | 提高 TTL 或改进刷新策略 |
| 登录请求占比 | > 20% 总请求 | TTL 增加 / 登录缓存加速 |
| 同时活跃生成数 | > 20 （单核） | 减少突发或启用第二实例 |
| 内存剩余 | < 150MB | 减少连接池 / 降日志级别 |

---
## 7. 风险与边界说明

- 过高 RPS 对单核无直接吞吐提升，只会增加队列长尾；用户感知变差。
- TTL 太低造成集中登录与额外 CPU、IO 开销；过高（>600s）则提升安全风险（被盗用窗口）。
- 并发>2（每用户）在单核上易造成上下文切换过多，不建议早期使用。
- 突发容量与连接池同步放大 >50 后收益递减，开始浪费内存与文件描述符。

---
## 8. 扩容策略（一旦进入下一阶段）

1. 启动第二实例（相同配置）+ 负载均衡（Round Robin 或基于活跃请求数）。
2. 将用户路由策略加入简单一致性哈希（减少频繁跨实例的 token/配额重建）。
3. 配额与用户数据如果增长过大：迁移到外部 Redis / KV 存储；DashMap 只保留活跃用户。
4. 指标接入 Prometheus + Grafana：展示 p50/p95 走势、429/401 速率、活跃生成数量。

---
## 9. 公式与速查表

```
# 单用户平均发起速率（长响应 + 思考）
λ_user ≈ 1 / (响应时长 + 思考时长)

# 总 Chat 峰值 RPS
λ_chat ≈ CCU * λ_user

# 全类型峰值 RPS（含检索等轻请求）
λ_total ≈ λ_chat * 1.3

# 建议全局 RPS 选型
RPS_config ≈ min( λ_total * 安全系数(2~3), 单核允许的活跃生成上限 / 平均生成时长 )

# 示例
CCU=50 → λ_user ≈ 1/60 → λ_chat ≈ 0.83 → λ_total ≈ 1.1
RPS_config 选 8 已足够（>7 × λ_total）
```

速查：
| CCU | 估算总RPS | 推荐 RPS_config |
|-----|-----------|----------------|
| 25 | ~0.6 | 6 |
| 50 | ~1.1 | 8 |
| 100 | ~2.2 | 12 |

---
## 10. 后续验证步骤

1. 调整 TTL=120，RPS=12，运行稳定性脚本（缩减 USER_COUNT=50）。
2. 记录 3 轮：p50/p95/p99、401/429 分布、登录次数。
3. 若 p95 降而 401≈0，则固定该配置；否则分别微调 TTL 和 RPS。
4. 埋点真实 ThinkTime（UI 前端打点），替换估算参数再回算。

---
## 11. 审阅清单

- [ ] 假设参数是否需要用真实埋点替换？
- [ ] 配置分档是否符合你的增长规划？
- [ ] 监控指标是否全部可采集（是否需要新增 metrics）？
- [ ] 扩容策略是否需提前准备脚本 / IaC？
- [ ] 风险条目是否需要补充安全相关项（速率防刷、Token撤销）？

---
## 12. 总结

当前配置 (RPS=20, TTL=60) 对真实预计负载明显偏高且 TTL 偏低，会造成不必要的登录轮换与潜在长尾排队。根据行业常规推算你真实峰值 RPS 低于 3，推荐将 RPS 下调到 8–12 并提升 TTL 至 120–180，以更好平衡稳定性与资源利用率。后续增长优先通过多实例水平扩展而不是继续提高单节点速率限制。

> 如需自动生成一个“调参建议”节或脚本，请提出下一步需求。
